---
title: "Brainstroke Predictive Modeling"
output:
  pdf_document: default
  html_document: default
date: "June 26th, 2023"
---
## Data obtained from Kaggle: https://www.kaggle.com/datasets/zzettrkalpakbal/full-filled-brain-stroke-dataset

# EDA

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, reuslts = "hide"}
library(corrplot)
library(readr)
library(dplyr)
library(ggplot2)
library(moments)
library(Hmisc)
library(pROC)
library(caret)
library(gbm)
library(knitr)
library(randomForest)
library(MASS)
library(randomForestExplainer)
library(lattice)
```

```{r}
getwd()
setwd("/Users/samantharivas/Documents/Brainstroke")

brain_stroke = read.csv("healthcare-dataset-stroke-data.csv")
head(brain_stroke, n = 5)
```

```{r}
#removing null values
brain_na = brain_stroke[-which(brain_stroke$bmi=="N/A"), ]
```

```{r}
#Types of data
str(brain_stroke) #data consists of numeric, character,  and integer variables

#Dimension of the data
dim(brain_stroke) 
```

```{r}
#Changing variables from character to factor to numeric
brain_stroke_fac<- brain_na %>% mutate_if(is.character, as.factor)
brain_stroke_num <- brain_stroke_fac %>% mutate_if(is.factor, as.numeric)

head(brain_stroke_num, n = 5)
str(brain_stroke_num) #dataset now consists of numeric and integer varaibles 
```

```{r}
# increase the size of the plot area
par(mfrow = c(3,4)) 

#identify outliers using boxplot
for (i in 1:ncol(brain_stroke_num)) {boxplot(brain_stroke_num[ ,i], 
                                             xlab = names(brain_stroke_num[i]),
                                             main = paste(names(
                                               brain_stroke_num[i]), "Boxplot"))
  }

```

Our group decided to keep outlier variables as we considered them an important factor in predicting brainstrokes.

```{r}
#check for duplicates
sum(duplicated(brain_stroke_num))
```

```{r}
#running a correlation test to drop variables 
correlation <- cor(brain_stroke_num)
dim(correlation)
corrplot(correlation, order = "hclust")
correlation
```

Dropping variables that have a less than 0.05 correlation significance to the predictor variable "stroke".

```{r}
#dropping columns id, residence_typem gender, bmi 
brain_drop=subset(brain_stroke_num, select=-c(id, Residence_type, gender, bmi))
head(brain_drop, n =5)
```

```{r}
#running a correlation test on the new df-brain_drop
correlation_drop <- cor(brain_drop)
dim(correlation_drop)
corrplot(correlation_drop, order = "hclust")
correlation_drop
```

```{r}
#skewness
skewness(brain_drop)
```

```{r}
summary(brain_drop)
```

```{r}
#histogram of the variables
hist.data.frame(brain_drop)

par(mfrow = c(3, 3))
for (i in 1:ncol(brain_drop)) {hist(brain_drop[ ,i], 
                                             xlab = names(brain_drop[i]),
                                             main = paste(names(
                                               brain_drop[i]), "Histogram"))
  }
```

```{r}
df <- brain_drop

head(df, n = 5)

# convert stroke numeric values in to factor ( 0 = No, 1 = Yes )
df$stroke <- ifelse(df$stroke == 0, "No","Yes")

head(df, n = 5)

#splitting the data set into test and train
set.seed(100)
inTrain <- createDataPartition(df$stroke, p = .80,list = FALSE)

train <- df[inTrain, ]
test <- df[-inTrain, ]


#balancing the training dataset

table(train$stroke) #4% of the training df is "yes"
to.resample <- which(train$stroke == "Yes") 

our.resample <- sample(x = to.resample, size = 1443, replace = TRUE) #resampling data to 30% yes  

our.resample <- train[our.resample, ]

train_rebalanced <- rbind(train, our.resample)

t.v1 <- table(train_rebalanced$stroke)
t.v2 <- rbind(t.v1, round(prop.table(t.v1), 4))
colnames(t.v2) <- c( "Stroke = No", "Stroke = Yes"); 
rownames(t.v2) <- c("Count", "Proportion")
t.v2 #data balanced to 30% yes and 70% no 

```
# Model Building Strategies 

## Boosted Trees Model 
```{r}
# defining Boosted Trees model
set.seed(100)

gbm.Grid <- expand.grid(.interaction.depth = seq(1, 3, 5),
                       .n.trees = seq(100, 1000, by = 100), 
                       .shrinkage = c(0.01, 0.1), 
                       .n.minobsinnode = seq(5, 10, 15))


stroke_gbm <- train(stroke~., 
                    data = train_rebalanced, 
                    method = "gbm", 
                    tuneGrid = gbm.Grid,
                    verbose = FALSE)

stroke_gbm$finalModel

plot(stroke_gbm, main = "Boosted Trees Model")

#re-sampling Boosted trees model
gbmResample <-stroke_gbm$results
gbmResample$Model <-"gbm"
head(gbmResample)

#finding most important predictors 
gbmImp <- varImp(stroke_gbm, scale = FALSE)

gbmImp

plot(gbmImp, 
     main = "Variable Importance for Boosted Trees Model")
# from the graph we can conclude age is the most important variable
# avg_glucose_level and hypertension are also important 


#defining levels of test$stroke to build confusion matrix + ROC 
test$stroke <- factor(test$stroke, levels = c("Yes", "No"))
               
levels(test$stroke)

# running predictions on the test data for Boosted Trees model 
gbm_prediction <- predict(stroke_gbm, newdata = test)
gbm_prediction_prob <- predict(stroke_gbm, 
                               newdata = test, 
                               type = "prob") 

test$gbmclass <- predict(stroke_gbm, test)
test$gbmprob <- gbm_prediction_prob[, "No"]

# creating a confusion matrix for Predicted No/Yes and Actual No/Yes
gbm_confusionMatrix <- confusionMatrix(data = gbm_prediction, 
                                       reference = test$stroke,
                                       positive = "No")

gbm_confusionMatrix

#ROC
gbm_roc <- roc(response = test$stroke, 
               predictor = test$gbmprob, 
               levels = rev(levels(test$stroke)))

plot(gbm_roc, main = "Boosted Trees ROC")

# calculate the AUC 
gbmroc_score <- auc(gbm_roc)

# print the AUC 
print(gbmroc_score)


```
## Random Forest Model
```{r}
# Finding the optimal number of variables to use in Randomforest model
errorvalues <- vector()
for (i in 3:10){
  temprf <- randomForest(as.factor(stroke)~.,
                         data = train_rebalanced, 
                         ntree = 1000, mtry = i)
  errorvalues[i] <- temprf$err.rate[nrow(temprf$err.rate),1]
}

plot(errorvalues, main = "Error Values")

# Creating Randomforest model
set.seed(100)
rfTune <- randomForest(as.factor(stroke)~., 
                       data = train_rebalanced, 
                       ntree = 1000, mtry = 5,
                       trControl = trainControl(method = "cv"), 
                       preProc = c("center", "scale"))
rfTune

# Defining levels of response variable
test$stroke <- factor(test$stroke, levels = c("Yes", "No"))
               
levels(test$stroke)

# Creating predictions on test data for Randomforest model
rf_prediction <- predict(rfTune, newdata = test)
rf_prediction_prob <- predict(rfTune, 
                               newdata = test, 
                               type = "prob") 

test$rfclass <- predict(rfTune, test)
test$rfprob <- rf_prediction_prob[, "No"]

# Confusion matrix for Randomforest model
rf_pred <- predict(rfTune, newdata = test[,-8])
rf_cm <- confusionMatrix(rf_pred, as.factor(test$stroke))
rf_cm

# Variable importance values for Random Forest
var_importance <- rfTune$importance[, "MeanDecreaseGini"]

# Sort variable importance values in descending order
sorted_indices <- order(var_importance)
sorted_importance <- var_importance[sorted_indices]
sorted_names <- names(var_importance)[sorted_indices]

# Plot Variable Importance
rfImp <-dotplot(sorted_names ~ sorted_importance, pch = 19,
                main = "Variable Importance for Random Forest Model",
                xlab = "Importance", ylab = "",
                type = c("p", "h"), panel.grid = "none")
rfImp

# Variable importance for Randomforest
#rfImp <- varImp(rfTune, scale = TRUE)
#rfImp

# Plot variable importance
#plot(rfImp, main = "Variable Importance for Random Forest Model")

# ROC curve for Randomforest model
rf_roc <- roc(response = test$stroke, predictor = test$rfprob, 
              levels = rev(levels(test$stroke)))

# Plot ROC curve for Randomforest model
plot(rf_roc, main = "Random Forest ROC")

# Calculate the AUC 
rfroc_score <- auc(rf_roc)

# Print the AUC (ROC score)
print(rfroc_score)
```
## Partial Least Squares Model
```{r}
# Partial Least Squares model 
set.seed(200)
preProc <- preProcess(train, method = c("center", "scale"))
ctrlpls <- trainControl(method="repeatedcv", repeats=5)

#pls model
pls <- train(stroke~., data = train_rebalanced, 
             method="pls", 
             ctrlpls=trainControl, 
             preProcess=c("center", "scale"), 
             tuneLength=20)
pls

plot(pls, main = "Partial Least Squares Model")

# Defining levels of stroke 
test$stroke=factor(test$stroke, levels=c("Yes", "No"))
levels(test$stroke)

# Creating predictions on the test data for PLS model
pls_pred <- predict(pls, 
                    newdata = test[,-8])

pls_prob <- predict(pls,
                    newdata = test[,-8], 
                    type = "prob")

test$plsclass <- predict(pls, test)
test$pls_prob <- pls_prob[,"No"]

# Confusion matrix for PLS
pls_cm <- confusionMatrix(as.factor(test$stroke), pls_pred)
pls_cm

# ROC for PLS 
pls_roc <- roc(response = test$stroke, 
               predictor = test$pls_prob, 
               levels = rev(levels(test$stroke)))
plot(pls_roc, main = "Partial Least Squares ROC")

# calculate the AUC 
plsroc_score <- auc(pls_roc)

# print the AUC 
print(plsroc_score)

# Variable importance for PLS 
varImppls <- varImp(pls)
varImppls

plot(varImppls, main = "Variable Importance for Partial Least Squares Model")

```

## Final Results 
```{r}
# Variable importance for all three models 
par(mfrow = c(2, 2))
plot(gbmImp, 
     main = "Variable Importance for Boosted Trees")

par(mfrow = c(1, 1))
par(mfrow = c(2, 2))

plot(rfImp, 
     main = "Variable Importance for Random Forest")

par(mfrow = c(1, 1))
par(mfrow = c(2, 2))

plot(varImppls, 
     main = "Variable Importance for Partial Least Squares")
par(mfrow = c(1, 1))
```
```{r}
# combine the three ROC curves into a data frame
roc_curves <- data.frame(
  Model = c(rep("GBM", length(gbm_roc$specificities)),
            rep("RF", length(rf_roc$specificities)),
            rep("PLS", length(pls_roc$specificities))),
  Specificity = c(gbm_roc$specificities,
                  rf_roc$specificities,
                  pls_roc$specificities),
  Sensitivity = c(gbm_roc$sensitivities,
                  rf_roc$sensitivities,
                  pls_roc$sensitivities)
)

# plot the ROC curves 
ggplot(roc_curves, aes(x = 1 - Specificity, y = Sensitivity, color = Model)) +
  geom_line() +
  labs(x = "False Positive Rate (1 - Specificity)", y = "True Positive Rate (Sensitivity)",
       title = "ROC Curves") +
  theme_minimal()

```
Our group has selected the Random Forest model as our optimal model. 
